{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search engine demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 1\n",
    "Αρχικά ξεκινάμε τρέχοντας μέσω CMD τις επόμενες εντολές:\n",
    "- pip install notebook\n",
    "- pip install beautifulsoup4\n",
    "- pip install requests\n",
    "- pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Λίστα με τα 10 URLs\n",
    "urls = [\n",
    "    'https://en.wikipedia.org/wiki/Python_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/JavaScript',\n",
    "    'https://en.wikipedia.org/wiki/Java_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/C_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/Ruby_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/HTML',\n",
    "    'https://en.wikipedia.org/wiki/C%2B%2B',\n",
    "    'https://en.wikipedia.org/wiki/Go_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/Swift_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/Kotlin'\n",
    "]\n",
    "\n",
    "# Συνάρτηση για να τραβήξουμε δεδομένα από κάθε URL\n",
    "def crawl_page(url):\n",
    "    print(f\"Crawling: {url}\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Εξαγωγή όλων των λέξεων από την σελίδα\n",
    "            # Επιλέγουμε τα tags που περιέχουν κείμενο: p (paragraphs), li (list items), span, a (links) και άλλα\n",
    "            text = []\n",
    "            for tag in soup.find_all(['p', 'li', 'span', 'a', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "                text.append(tag.get_text())\n",
    "            \n",
    "            # Συνενώνουμε όλα τα κείμενα και καθαρίζουμε από περιττά κενά\n",
    "            full_text = ' '.join(text)\n",
    "            # Καθαρισμός κειμένου (π.χ. αφαιρούμε περιττές λευκές περιοχές)\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "            \n",
    "            return cleaned_text\n",
    "        else:\n",
    "            print(f\"Failed to retrieve {url}\")\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error while crawling {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Δημιουργία λεξικού για αποθήκευση του πλήρους κειμένου ανά URL\n",
    "text_dict = {}\n",
    "\n",
    "# Κάνουμε crawl τις 10 σελίδες\n",
    "for url in urls:\n",
    "    page_text = crawl_page(url)\n",
    "    text_dict[url] = page_text\n",
    "\n",
    "# Αποθήκευση των δεδομένων σε αρχείο JSON\n",
    "with open('programming_languages_text.json', 'w') as file:\n",
    "    json.dump(text_dict, file, indent=4)\n",
    "\n",
    "print(\"Data saved to programming_languages_text.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ο παραπάνω κώδικας υλοποιεί μια διαδικασία web scraping για να τραβήξει κείμενο από 10 σελίδες της Wikipedia που σχετίζονται με γλώσσες προγραμματισμού. Αναλυτικά:\n",
    "\n",
    "1. **Λίστα URLs**: Ορίζεται μια λίστα με 10 URLs που περιέχουν πληροφορίες για γλώσσες προγραμματισμού, όπως Python, Java, C, HTML κ.λπ.\n",
    "\n",
    "2. **Συνάρτηση crawl_page**:\n",
    "- Κάνει HTTP αίτημα (GET) σε κάθε URL.\n",
    "- Αν η απάντηση είναι επιτυχής (κωδικός 200), χρησιμοποιεί το BeautifulSoup για να αναλύσει το HTML περιεχόμενο της σελίδας.\n",
    "- Εξάγει κείμενο από διάφορα HTML tags όπως *p, li, span, a, h1-h6*.\n",
    "- Συνενώνει το κείμενο από όλα τα tags σε μια ενιαία συμβολοσειρά.\n",
    "- Καθαρίζει το κείμενο από περιττά κενά και επιστρέφει το τελικό καθαρό κείμενο.\n",
    "\n",
    "3. **Αποθήκευση Δεδομένων**:\n",
    "- Τα δεδομένα αποθηκεύονται σε ένα λεξικό text_dict όπου το κλειδί είναι το URL και η τιμή είναι το εξαγόμενο κείμενο από τη σελίδα.\n",
    "- Τέλος, τα δεδομένα αποθηκεύονται σε αρχείο JSON με το όνομα *programming_languages_text.json*.\n",
    "\n",
    "4. **Αρχειοθέτηση**:\n",
    "Το JSON αρχείο που δημιουργείται, περιέχει τα κείμενα από όλες τις σελίδες, τα οποία μπορούν να χρησιμοποιηθούν για περαιτέρω επεξεργασία, όπως δημιουργία ενός inverted index ή κατάταξη εγγράφων."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step 1](./project/images/step_1.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 2\n",
    "\n",
    "- **Κατέβασμα των απαιτούμενων πόρων του NLTK**: \n",
    "Χρησιμοποιούμε το NLTK για να κατεβάσουμε τα δεδομένα που απαιτούνται για την επεξεργασία του κειμένου, όπως οι stopwords και η λέξη-ρίζα λεξικογράφηση.\n",
    "- **Φόρτωση stopwords**: \n",
    "Οι stopwords είναι κοινές λέξεις που συνήθως αφαιρούνται κατά την επεξεργασία φυσικής γλώσσας, όπως \"the\", \"is\", κλπ.\n",
    "- **Αρχικοποίηση του Stemming και Lemmatization**: \n",
    "ο stemming απομακρύνει τα κατάληξη των λέξεων για να επιστρέψει τη ρίζα της λέξης, ενώ το lemmatization επιστρέφει την κανονική μορφή της λέξης.\n",
    "- **Διαδικασία καθαρισμού**: \n",
    "Ο καθαρισμός του κειμένου περιλαμβάνει το tokenization, την αφαίρεση stopwords, την αφαίρεση της στίξης, και την εφαρμογή του stemming και του lemmatization.\n",
    "- **Αποθήκευση των επεξεργασμένων δεδομένων**: \n",
    "Τα επεξεργασμένα δεδομένα αποθηκεύονται σε ένα νέο αρχείο JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Κατεβάζουμε τους απαιτούμενους πόρους του NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Ορίζουμε τις διαδρομές των αρχείων εισόδου και εξόδου\n",
    "input_json_path = 'programming_languages_text.json'\n",
    "output_json_path = 'processed_programming_languages_text.json'\n",
    "\n",
    "# Φορτώνουμε τις λέξεις κλειδιά (stopwords)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Αρχικοποιούμε τον αλγόριθμο stemming και lemmatization\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Debug: Εμφανίζουμε τις stopwords που χρησιμοποιούνται\n",
    "print(\"Stopwords used:\", stop_words)\n",
    "\n",
    "# Ορίζουμε μία συνάρτηση για τον καθαρισμό του κειμένου\n",
    "def clean_text(text):\n",
    "    # Κάνουμε tokenization του κειμένου σε λέξεις\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Αφαιρούμε τις stopwords και την στίξη\n",
    "    cleaned_words = [\n",
    "        word.lower() for word in words \n",
    "        if word.lower() not in stop_words and word not in string.punctuation\n",
    "    ]\n",
    "    \n",
    "    # Εφαρμόζουμε το stemming\n",
    "    stemmed_words = [stemmer.stem(word) for word in cleaned_words]\n",
    "    \n",
    "    # Εφαρμόζουμε το lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "    \n",
    "    # Ενώνουμε τις καθαρές, stemmed και lemmatized λέξεις πίσω σε μία συμβολοσειρά\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Διαβάζουμε το αρχείο εισόδου JSON\n",
    "with open(input_json_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Επεξεργαζόμαστε τα δεδομένα κειμένου και αποθηκεύουμε την καθαρισμένη εκδοχή μόνο\n",
    "processed_data = {}\n",
    "for key, value in data.items():\n",
    "    processed_value = clean_text(value)\n",
    "    processed_data[key] = processed_value\n",
    "\n",
    "# Αποθηκεύουμε τα επεξεργασμένα δεδομένα στο αρχείο εξόδου JSON\n",
    "with open(output_json_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(processed_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Τα επεξεργασμένα δεδομένα αποθηκεύτηκαν στο {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step2](./project/images/step_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 3\n",
    "\n",
    "Για το βήμα 3, χρειάστηκε να εκτελέσουμε την παρακάτω εντολή (για τη βιβλιοθήκη nltk):\n",
    "- pip install nltk\n",
    "##\n",
    "- **Διαβάζουμε τα προεπεξεργασμένα δεδομένα**: Ανοίγουμε το αρχείο JSON που περιέχει τα επεξεργασμένα δεδομένα κειμένου που έχουμε αποθηκεύσει προηγουμένως.\n",
    "\n",
    "- **Αρχικοποιούμε το ανεστραμμένο ευρετήριο (Inverted Index)**: Το ανεστραμμένο ευρετήριο είναι μία δομή δεδομένων που μας επιτρέπει να εντοπίσουμε γρήγορα σε ποια έγγραφα εμφανίζεται κάθε λέξη.\n",
    "\n",
    "- **Δημιουργία του ανεστραμμένου ευρετηρίου**: Για κάθε κείμενο που έχουμε επεξεργαστεί, διαχωρίζουμε το κείμενο σε λέξεις και προσθέτουμε την κάθε λέξη στο ανεστραμμένο ευρετήριο. Κάθε λέξη θα δείχνει σε ποια έγγραφα (ταυτοποιημένα με doc_id) εμφανίζεται.\n",
    "\n",
    "- **Αποθήκευση του ανεστραμμένου ευρετηρίου**: Αποθηκεύουμε το ανεστραμμένο ευρετήριο σε ένα νέο αρχείο JSON για μελλοντική χρήση.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Διαβάζουμε τα προεπεξεργασμένα δεδομένα\n",
    "with open('processed_programming_languages_text.json', 'r', encoding='utf-8') as file:\n",
    "    processed_data = json.load(file)\n",
    "\n",
    "# Αρχικοποιούμε το ανεστραμμένο ευρετήριο (Inverted Index)\n",
    "inverted_index = {}\n",
    "\n",
    "# Δημιουργούμε το ανεστραμμένο ευρετήριο\n",
    "for doc_id, text in processed_data.items():\n",
    "    # Διαχωρίζουμε το κείμενο σε λέξεις\n",
    "    words = text.split()\n",
    "    \n",
    "    for word in words:\n",
    "        # Προσθέτουμε τη λέξη στο ανεστραμμένο ευρετήριο\n",
    "        if word not in inverted_index:\n",
    "            inverted_index[word] = []  # Αρχικοποιούμε μία κενή λίστα για τη λέξη\n",
    "        if doc_id not in inverted_index[word]:\n",
    "            inverted_index[word].append(doc_id)\n",
    "\n",
    "# Αποθηκεύουμε το ανεστραμμένο ευρετήριο σε αρχείο\n",
    "output_index_path = 'inverted_index.json'\n",
    "with open(output_index_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(inverted_index, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Το ανεστραμμένο ευρετήριο αποθηκεύτηκε στο {output_index_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step 3](./project/images/step_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 4\n",
    "\n",
    "- **Διαβάζουμε το ανεστραμμένο ευρετήριο**: Φορτώνουμε το ανεστραμμένο ευρετήριο από το αρχείο JSON που δημιουργήσαμε προηγουμένως.\n",
    "\n",
    "- **Επεξεργασία Boolean Query**: Η συνάρτηση boolean_query_processor επεξεργάζεται ένα Boolean query (όπως \"python AND java\") και επιστρέφει τα έγγραφα που ταιριάζουν με την αναζήτηση. Χρησιμοποιεί τελεστές όπως \"AND\", \"OR\", \"NOT\".\n",
    "\n",
    "- **Διαχωρισμός του query σε όρους και τελεστές**: Στην συνάρτηση parse_query, το query διαχωρίζεται σε όρους και τελεστές (AND, OR, NOT). Αυτοί οι τελεστές χρησιμοποιούνται για να συνδυαστούν τα αποτελέσματα από το ανεστραμμένο ευρετήριο.\n",
    "\n",
    "- **Αναζήτηση για κάθε όρο**: Η συνάρτηση get_documents επιστρέφει τα έγγραφα που περιέχουν κάθε όρο από το ανεστραμμένο ευρετήριο.\n",
    "\n",
    "- **Συνδυασμός των αποτελεσμάτων με βάση τους τελεστές**: Χρησιμοποιούμε τελεστές για να συνδυάσουμε τα αποτελέσματα των όρων και να υπολογίσουμε ποια έγγραφα ταιριάζουν με το query. Αν ο τελεστής είναι \"AND\", παίρνουμε τα κοινά έγγραφα (διασταύρωση), αν είναι \"OR\", παίρνουμε τη ένωση, και αν είναι \"NOT\", παίρνουμε τη διαφορά.\n",
    "\n",
    "- **Παράδειγμα ελέγχου**: Ενδεικτικά, εκτελούμε το query \"python AND java\" και εκτυπώνουμε τα έγγραφα που ταιριάζουν με το query.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*boolean_query_processor.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Διαβάζουμε το ανεστραμμένο ευρετήριο\n",
    "with open('inverted_index.json', 'r', encoding='utf-8') as file:\n",
    "    inverted_index = json.load(file)\n",
    "\n",
    "def boolean_query_processor(query, inverted_index):\n",
    "    \"\"\"\n",
    "    Επεξεργάζεται ένα Boolean query και επιστρέφει τα αναγνωριστικά των εγγράφων που ταιριάζουν.\n",
    "    \"\"\"\n",
    "    def parse_query(query):\n",
    "        # Διαχωρίζουμε το query σε όρους και τελεστές\n",
    "        tokens = query.split()\n",
    "        terms = []\n",
    "        operators = []\n",
    "        for token in tokens:\n",
    "            if token in {\"AND\", \"OR\", \"NOT\"}:\n",
    "                operators.append(token)\n",
    "            else:\n",
    "                terms.append(token)\n",
    "        return terms, operators\n",
    "\n",
    "    def get_documents(term):\n",
    "        # Παίρνουμε τα έγγραφα για έναν όρο από το ανεστραμμένο ευρετήριο\n",
    "        return set(inverted_index.get(term, []))\n",
    "\n",
    "    terms, operators = parse_query(query)\n",
    "    if not terms:\n",
    "        return set()  # Αν δεν υπάρχουν όροι, επιστρέφουμε κενό σύνολο\n",
    "\n",
    "    # Αρχικοποιούμε το σύνολο των αποτελεσμάτων με τον πρώτο όρο\n",
    "    result = get_documents(terms[0])\n",
    "\n",
    "    # Επεξεργαζόμαστε τους τελεστές και συνδυάζουμε τα αποτελέσματα\n",
    "    for i, operator in enumerate(operators):\n",
    "        next_term_docs = get_documents(terms[i + 1])\n",
    "        if operator == \"AND\":\n",
    "            result = result.intersection(next_term_docs)  # Διασταύρωση (AND)\n",
    "        elif operator == \"OR\":\n",
    "            result = result.union(next_term_docs)  # Ένωση (OR)\n",
    "        elif operator == \"NOT\":\n",
    "            result = result.difference(next_term_docs)  # Διαφορά (NOT)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Παράδειγμα ελέγχου\n",
    "query = \"python AND java\"\n",
    "matching_docs = boolean_query_processor(query, inverted_index)\n",
    "print(f\"Έγγραφα που ταιριάζουν με το '{query}': {matching_docs}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step 4i](./project/images/step_4_i.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Διαβάζουμε το ανεστραμμένο ευρετήριο**: Ανοίγουμε το αρχείο *inverted_index.json* και φορτώνουμε το αντίστροφο ευρετήριο.\n",
    "\n",
    "- **Διαβάζουμε τα επεξεργασμένα δεδομένα**: Φορτώνουμε το αρχείο με τα προεπεξεργασμένα δεδομένα κειμένου (*processed_programming_languages_text.json*).\n",
    "\n",
    "- **Συνάρτηση για να βρούμε τα έγγραφα που ταιριάζουν με το query**: Η συνάρτηση `get_matching_docs` παίρνει το query, το διαχωρίζει σε όρους και βρίσκει ποια έγγραφα περιέχουν αυτούς τους όρους με τη βοήθεια του ανεστραμμένου ευρετηρίου.\n",
    "\n",
    "- **Συνάρτηση για να υπολογίσουμε το TF-IDF και να κατατάξουμε τα έγγραφα**: Η συνάρτηση `compute_tf_idf` υπολογίζει την ομοιότητα συνημίτονου (cosine similarity) ανάμεσα στο query και τα έγγραφα. Αυτό γίνεται μέσω του υπολογισμού του TF-IDF των λέξεων του query και των εγγράφων.\n",
    "\n",
    "- **Εμφάνιση των αποτελεσμάτων**: Τα έγγραφα κατατάσσονται με βάση την ομοιότητα τους με το query και εμφανίζονται στον χρήστη."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tfidf_ranking.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Διαβάζουμε το ανεστραμμένο ευρετήριο\n",
    "with open('inverted_index.json', 'r', encoding='utf-8') as file:\n",
    "    inverted_index = json.load(file)\n",
    "\n",
    "# Διαβάζουμε τα επεξεργασμένα δεδομένα\n",
    "with open('processed_programming_languages_text.json', 'r', encoding='utf-8') as file:\n",
    "    processed_data = json.load(file)\n",
    "\n",
    "# Συνάρτηση για να βρούμε τα έγγραφα που ταιριάζουν με το query\n",
    "def get_matching_docs(query):\n",
    "    query_terms = query.lower().split()  # Διαχωρίζουμε το query σε όρους\n",
    "    matching_docs = set()\n",
    "\n",
    "    # Ελέγχουμε ποια έγγραφα ταιριάζουν με τους όρους του query\n",
    "    for term in query_terms:\n",
    "        if term in inverted_index:\n",
    "            matching_docs.update(inverted_index[term])\n",
    "\n",
    "    return list(matching_docs)\n",
    "\n",
    "# Συνάρτηση για να υπολογίσουμε το TF-IDF και να κατατάξουμε τα έγγραφα\n",
    "def compute_tf_idf(query, matching_docs, processed_data):\n",
    "    # Προετοιμάζουμε το corpus: περιλαμβάνουμε μόνο τα έγγραφα που ταιριάζουν\n",
    "    corpus = [processed_data[doc_id] for doc_id in matching_docs]\n",
    "    \n",
    "    # Προσθέτουμε το query ως τελευταίο στοιχείο στο corpus\n",
    "    corpus.append(query)\n",
    "\n",
    "    # Χρησιμοποιούμε τον TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Παίρνουμε το vector του query (τελευταία γραμμή του matrix)\n",
    "    query_vector = tfidf_matrix[-1]\n",
    "\n",
    "    # Υπολογίζουμε την ομοιότητα συνημίτονου (cosine similarity) μεταξύ του query και κάθε εγγράφου\n",
    "    cosine_similarities = (tfidf_matrix[:-1] @ query_vector.T).toarray().flatten()\n",
    "\n",
    "    # Ταιριάζουμε κάθε έγγραφο με την βαθμολογία της ομοιότητας\n",
    "    ranked_docs = sorted(\n",
    "        zip(matching_docs, cosine_similarities),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return ranked_docs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ζητάμε από τον χρήστη να εισάγει ένα query\n",
    "    query = input(\"Εισάγετε το query σας (κατάταξη TF-IDF): \").strip()\n",
    "\n",
    "    # Βρίσκουμε τα έγγραφα που ταιριάζουν με το query\n",
    "    matching_docs = get_matching_docs(query)\n",
    "    \n",
    "    if not matching_docs:\n",
    "        print(\"Δεν βρέθηκαν έγγραφα που να ταιριάζουν.\")\n",
    "    else:\n",
    "        # Υπολογίζουμε και κατατάσσουμε τα έγγραφα με βάση το TF-IDF\n",
    "        ranked_docs = compute_tf_idf(query, matching_docs, processed_data)\n",
    "\n",
    "        # Εμφανίζουμε τα αποτελέσματα\n",
    "        print(\"\\nΚαταταγμένα αποτελέσματα:\")\n",
    "        for doc_id, score in ranked_docs:\n",
    "            print(f\"{doc_id}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step 4ii](./project/images/step_4_ii.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Διαβάζουμε το ανεστραμμένο ευρετήριο**: Φορτώνουμε το ανεστραμμένο ευρετήριο από το αρχείο *inverted_index.json*.\n",
    "\n",
    "- **Διαβάζουμε τα επεξεργασμένα δεδομένα**: Φορτώνουμε το αρχείο με τα προεπεξεργασμένα δεδομένα κειμένου από το αρχείο *processed_programming_languages_text.json*.\n",
    "\n",
    "- **Συνάρτηση για κατάταξη με BM25**: Η συνάρτηση `bm25_ranking` χρησιμοποιεί τον αλγόριθμο BM25 για να κατατάξει τα έγγραφα με βάση την ομοιότητα του query με τα έγγραφα. Για κάθε έγγραφο, υπολογίζουμε τη βαθμολογία του και τα ταξινομούμε σε φθίνουσα σειρά.\n",
    "\n",
    "- **Κύρια συνάρτηση της μηχανής αναζήτησης**: Η συνάρτηση `search_engine` είναι η κεντρική λειτουργία της μηχανής αναζήτησης. Επιτρέπει στον χρήστη να εισάγει ένα query και να επιλέξει τη μέθοδο κατάταξης (Boolean, TF-IDF ή BM25). Παρουσιάζει τα αποτελέσματα του query με την επιλεγμένη μέθοδο κατάταξης.\n",
    "\n",
    "- **Επιλογή μεθόδου κατάταξης**: Ο χρήστης μπορεί να επιλέξει την μέθοδο κατάταξης (Boolean, TF-IDF, BM25) για τα αποτελέσματα της αναζήτησης.\n",
    "\n",
    "- **Εμφάνιση καταταγμένων αποτελεσμάτων**: Τα αποτελέσματα του query εμφανίζονται με την επιλεγμένη μέθοδο κατάταξης και κάθε έγγραφο εμφανίζεται με τη σχετική του βαθμολογία."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*search_engine.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tfidf_ranking import compute_tf_idf\n",
    "from boolean_query_processor import boolean_query_processor\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Διαβάζουμε το ανεστραμμένο ευρετήριο\n",
    "with open(\"inverted_index.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    inverted_index = json.load(f)\n",
    "\n",
    "# Διαβάζουμε τα επεξεργασμένα δεδομένα\n",
    "with open(\"processed_programming_languages_text.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# Συνάρτηση για κατάταξη με BM25\n",
    "def bm25_ranking(query, matching_docs, processed_data):\n",
    "    # Tokenize (διαχωρίζουμε σε λέξεις) τα έγγραφα\n",
    "    tokenized_docs = [doc.split() for doc in processed_data.values()]\n",
    "    \n",
    "    # Δημιουργούμε το αντικείμενο BM25\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    # Διαχωρίζουμε το query σε λέξεις\n",
    "    query_tokens = query.split()\n",
    "    \n",
    "    # Υπολογίζουμε τις βαθμολογίες (scores) του query\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    \n",
    "    # Συνδυάζουμε τα έγγραφα με τις αντίστοιχες βαθμολογίες τους\n",
    "    doc_score_pairs = [(doc, score) for doc, score in zip(processed_data.keys(), scores) if doc in matching_docs]\n",
    "    \n",
    "    # Ταξινομούμε τα έγγραφα κατά φθίνουσα βαθμολογία\n",
    "    ranked_results = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [doc for doc, _ in ranked_results]\n",
    "\n",
    "# Κύρια συνάρτηση της μηχανής αναζήτησης\n",
    "def search_engine():\n",
    "    print(\"Καλώς ήρθατε στην Μηχανή Αναζήτησης!\")\n",
    "    print(\"Πληκτρολογήστε το query σας χρησιμοποιώντας Boolean τελεστές (AND, OR, NOT).\")\n",
    "    print(\"Παράδειγμα: python AND java OR javascript\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"Εισάγετε το query σας (ή πληκτρολογήστε 'exit' για έξοδο): \").strip()\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Αντίο!\")\n",
    "            break\n",
    "\n",
    "        # Επεξεργαζόμαστε το query χρησιμοποιώντας την Boolean αναζήτηση\n",
    "        matching_docs = boolean_query_processor(query, inverted_index)\n",
    "        if not matching_docs:\n",
    "            print(f\"Δεν βρέθηκαν έγγραφα που να ταιριάζουν με το query: {query}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nΈγγραφα που ταιριάζουν με το '{query}': {matching_docs}\")\n",
    "\n",
    "        # Επιλογή μεθόδου κατάταξης από τον χρήστη\n",
    "        print(\"\\nΕπιλέξτε μέθοδο κατάταξης:\")\n",
    "        print(\"1. Boolean Αναζήτηση (Προεπιλογή)\")\n",
    "        print(\"2. Κατάταξη TF-IDF\")\n",
    "        print(\"3. Κατάταξη BM25\")\n",
    "        choice = input(\"Εισάγετε τον αριθμό της επιλογής σας (1, 2 ή 3): \").strip()\n",
    "\n",
    "        if choice == \"2\":\n",
    "            ranked_docs = compute_tf_idf(query, matching_docs, processed_data)\n",
    "            print(\"\\nΚαταταγμένα αποτελέσματα με TF-IDF:\")\n",
    "        elif choice == \"3\":\n",
    "            ranked_docs = bm25_ranking(query, matching_docs, processed_data)\n",
    "            print(\"\\nΚαταταγμένα αποτελέσματα με BM25:\")\n",
    "        else:\n",
    "            ranked_docs = list(matching_docs)\n",
    "            print(\"\\nΑποτελέσματα Boolean Αναζήτησης:\")\n",
    "\n",
    "        # Εμφάνιση των καταταγμένων αποτελεσμάτων\n",
    "        for rank, doc in enumerate(ranked_docs, start=1):\n",
    "            print(f\"{rank}. {doc}\")\n",
    "\n",
    "# Εκκίνηση της μηχανής αναζήτησης\n",
    "if __name__ == \"__main__\":\n",
    "    search_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ακολουθεί ενδεικτική εκτέλεση.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\Users\\Gregory\\Desktop\\project>python search_engine.py\n",
    "Documents matching 'python AND java': {'https://en.wikipedia.org/wiki/Ruby_(programming_language)', 'https://en.wikipedia.org/wiki/Java_(programming_language)', 'https://en.wikipedia.org/wiki/C_(programming_language)', 'https://en.wikipedia.org/wiki/Python_(programming_language)', 'https://en.wikipedia.org/wiki/Swift_(programming_language)', 'https://en.wikipedia.org/wiki/JavaScript', 'https://en.wikipedia.org/wiki/C%2B%2B', 'https://en.wikipedia.org/wiki/Go_(programming_language)'}\n",
    "Welcome to the Search Engine!\n",
    "Type your query using Boolean operators (AND, OR, NOT).\n",
    "Example: python AND java OR javascript\n",
    "\n",
    "Enter your query (or type 'exit' to quit): java or hello\n",
    "\n",
    "Documents matching 'java or hello': {'https://en.wikipedia.org/wiki/Ruby_(programming_language)', 'https://en.wikipedia.org/wiki/Java_(programming_language)', 'https://en.wikipedia.org/wiki/C_(programming_language)', 'https://en.wikipedia.org/wiki/Python_(programming_language)', 'https://en.wikipedia.org/wiki/Swift_(programming_language)', 'https://en.wikipedia.org/wiki/JavaScript', 'https://en.wikipedia.org/wiki/C%2B%2B', 'https://en.wikipedia.org/wiki/Go_(programming_language)'}\n",
    "\n",
    "Choose a ranking method:\n",
    "1. Boolean Retrieval (Default)\n",
    "2. TF-IDF Ranking\n",
    "3. BM25 Ranking\n",
    "Enter the number of your choice (1, 2, or 3): 1\n",
    "\n",
    "Boolean Retrieval Results:\n",
    "1. https://en.wikipedia.org/wiki/Ruby_(programming_language)\n",
    "2. https://en.wikipedia.org/wiki/Java_(programming_language)\n",
    "3. https://en.wikipedia.org/wiki/C_(programming_language)\n",
    "4. https://en.wikipedia.org/wiki/Python_(programming_language)\n",
    "5. https://en.wikipedia.org/wiki/Swift_(programming_language)\n",
    "6. https://en.wikipedia.org/wiki/JavaScript\n",
    "7. https://en.wikipedia.org/wiki/C%2B%2B\n",
    "8. https://en.wikipedia.org/wiki/Go_(programming_language)\n",
    "Enter your query (or type 'exit' to quit): java or hello\n",
    "\n",
    "Documents matching 'java or hello': {'https://en.wikipedia.org/wiki/Ruby_(programming_language)', 'https://en.wikipedia.org/wiki/Java_(programming_language)', 'https://en.wikipedia.org/wiki/C_(programming_language)', 'https://en.wikipedia.org/wiki/Python_(programming_language)', 'https://en.wikipedia.org/wiki/Swift_(programming_language)', 'https://en.wikipedia.org/wiki/JavaScript', 'https://en.wikipedia.org/wiki/C%2B%2B', 'https://en.wikipedia.org/wiki/Go_(programming_language)'}\n",
    "\n",
    "Choose a ranking method:\n",
    "1. Boolean Retrieval (Default)\n",
    "2. TF-IDF Ranking\n",
    "3. BM25 Ranking\n",
    "Enter the number of your choice (1, 2, or 3): 2\n",
    "\n",
    "TF-IDF Ranked Results:\n",
    "1. ('https://en.wikipedia.org/wiki/Java_(programming_language)', np.float64(0.25966958427207704))\n",
    "2. ('https://en.wikipedia.org/wiki/JavaScript', np.float64(0.01689162517913656))\n",
    "3. ('https://en.wikipedia.org/wiki/C_(programming_language)', np.float64(0.015636927175054036))\n",
    "4. ('https://en.wikipedia.org/wiki/C%2B%2B', np.float64(0.01499599173627299))\n",
    "5. ('https://en.wikipedia.org/wiki/Go_(programming_language)', np.float64(0.012284060668750124))\n",
    "6. ('https://en.wikipedia.org/wiki/Ruby_(programming_language)', np.float64(0.007483638885609637))\n",
    "7. ('https://en.wikipedia.org/wiki/Swift_(programming_language)', np.float64(0.006847389333614802))\n",
    "8. ('https://en.wikipedia.org/wiki/Python_(programming_language)', np.float64(0.005532624249020468))\n",
    "Enter your query (or type 'exit' to quit): java or hello\n",
    "\n",
    "Documents matching 'java or hello': {'https://en.wikipedia.org/wiki/Ruby_(programming_language)', 'https://en.wikipedia.org/wiki/Java_(programming_language)', 'https://en.wikipedia.org/wiki/C_(programming_language)', 'https://en.wikipedia.org/wiki/Python_(programming_language)', 'https://en.wikipedia.org/wiki/Swift_(programming_language)', 'https://en.wikipedia.org/wiki/JavaScript', 'https://en.wikipedia.org/wiki/C%2B%2B', 'https://en.wikipedia.org/wiki/Go_(programming_language)'}\n",
    "\n",
    "Choose a ranking method:\n",
    "1. Boolean Retrieval (Default)\n",
    "2. TF-IDF Ranking\n",
    "3. BM25 Ranking\n",
    "Enter the number of your choice (1, 2, or 3): 3\n",
    "\n",
    "BM25 Ranked Results:\n",
    "1. https://en.wikipedia.org/wiki/Java_(programming_language)\n",
    "2. https://en.wikipedia.org/wiki/C_(programming_language)\n",
    "3. https://en.wikipedia.org/wiki/C%2B%2B\n",
    "4. https://en.wikipedia.org/wiki/JavaScript\n",
    "5. https://en.wikipedia.org/wiki/Go_(programming_language)\n",
    "6. https://en.wikipedia.org/wiki/Swift_(programming_language)\n",
    "7. https://en.wikipedia.org/wiki/Python_(programming_language)\n",
    "8. https://en.wikipedia.org/wiki/Ruby_(programming_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SearchEngineEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Φόρτωση του Αντίστροφου Ευρετηρίου**:\n",
    "\n",
    "Η πρώτη συνάρτηση, *load_inverted_index*, φορτώνει το αντίστροφο ευρετήριο από ένα αρχείο JSON. Αν το αρχείο δεν υπάρχει, η συνάρτηση επιστρέφει None και εκτυπώνει μήνυμα λάθους. Διαφορετικά, το αρχείο διαβάζεται και επιστρέφεται το αντίστροφο ευρετήριο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Φόρτωση του ανεστραμμένου ευρετηρίου από το αρχείο JSON\n",
    "def load_inverted_index(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return None\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        inverted_index = json.load(f)\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Επεξεργασία Boolean Queries**:\n",
    "\n",
    "Η συνάρτηση `boolean_query_processor` είναι υπεύθυνη για την επεξεργασία του Boolean query που παρέχεται από τον χρήστη. Αν το query περιέχει τις λέξεις κλειδιά AND, OR, ή NOT, η συνάρτηση θα επεξεργαστεί τα αντίστοιχα αποτελέσματα χρησιμοποιώντας τις αντίστοιχες λογικές πράξεις. Αν το query δεν περιέχει κανένα από αυτά τα λογικά τελεστικά, απλώς επιστρέφει τα έγγραφα που περιέχουν τον πρώτο όρο του query.\n",
    "\n",
    "- Αν το query περιέχει AND, επιστρέφονται τα έγγραφα που περιέχουν όλους τους όρους του query.\n",
    "- Αν το query περιέχει OR, επιστρέφονται τα έγγραφα που περιέχουν τουλάχιστον έναν από τους όρους.\n",
    "- Αν το query περιέχει NOT, επιστρέφονται τα έγγραφα που περιέχουν τον πρώτο όρο, αλλά χωρίς τους υπόλοιπους."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Συνάρτηση για την επεξεργασία Boolean queries και την επιστροφή των ταιριαστών εγγράφων\n",
    "def boolean_query_processor(query, inverted_index):\n",
    "    query_terms = query.lower().split(' ')\n",
    "    if 'and' in query_terms:\n",
    "        terms = [term for term in query_terms if term != 'and']\n",
    "        matching_docs = set(inverted_index.get(terms[0], []))\n",
    "        for term in terms[1:]:\n",
    "            matching_docs &= set(inverted_index.get(term, []))\n",
    "    elif 'or' in query_terms:\n",
    "        terms = [term for term in query_terms if term != 'or']\n",
    "        matching_docs = set(inverted_index.get(terms[0], []))\n",
    "        for term in terms[1:]:\n",
    "            matching_docs |= set(inverted_index.get(term, []))\n",
    "    elif 'not' in query_terms:\n",
    "        terms = [term for term in query_terms if term != 'not']\n",
    "        matching_docs = set(inverted_index.get(terms[0], []))\n",
    "        for term in terms[1:]:\n",
    "            matching_docs -= set(inverted_index.get(term, []))\n",
    "    else:\n",
    "        matching_docs = set(inverted_index.get(query_terms[0], []))\n",
    "\n",
    "    return matching_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Υπολογισμός Ακρίβειας, Ανάκτησης και F1-Score**:\n",
    "\n",
    "Η συνάρτηση `evaluate_metrics` υπολογίζει την ακρίβεια, την ανάκτηση και το F1-Score για τα έγγραφα που ταιριάζουν με το query. Αυτά τα μέτρα χρησιμοποιούνται συχνά για την αξιολόγηση της απόδοσης ενός συστήματος αναζήτησης:\n",
    "\n",
    "- **Ακρίβεια (Precision)**: Το ποσοστό των ταιριαστών εγγράφων που είναι πραγματικά συναφή με το query.\n",
    "- **Ανάκτηση (Recall)**: Το ποσοστό των συναφών εγγράφων που ανακτήθηκαν από το σύστημα.\n",
    "- **F1-Score**: Το αρμονικό μέσο της ακρίβειας και της ανάκτησης, το οποίο προσφέρει μια ενιαία μέτρηση.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Συνάρτηση για τον υπολογισμό της ακρίβειας, ανάκτησης και F1-Score\n",
    "def evaluate_metrics(matching_docs, relevant_docs):\n",
    "    relevant_doc_keys = set(relevant_docs.keys())\n",
    "    \n",
    "    tp = len(matching_docs & relevant_doc_keys)\n",
    "    fp = len(matching_docs - relevant_doc_keys)\n",
    "    fn = len(relevant_doc_keys - matching_docs)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Υπολογισμός του Mean Average Precision (MAP)**:\n",
    "\n",
    "Η συνάρτηση `mean_average_precision` υπολογίζει το Mean Average Precision για μια σειρά από queries. Ο μέσος όρος των AP (Average Precision) για κάθε query υπολογίζεται και χρησιμοποιείται για να πάρουμε το MAP score.\n",
    "\n",
    "- **Average Precision (AP)**: Ο υπολογισμός της ακρίβειας για κάθε θέση στο σύνολο των αποτελεσμάτων, με βάση τη σειρά κατάταξης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Συνάρτηση για τον υπολογισμό του Mean Average Precision (MAP)\n",
    "def mean_average_precision(query_results, relevant_docs_for_queries):\n",
    "    average_precision_scores = []\n",
    "    for query, retrieved_docs in query_results.items():\n",
    "        relevant_docs = relevant_docs_for_queries.get(query, {})\n",
    "        ap = average_precision(retrieved_docs, relevant_docs)\n",
    "        average_precision_scores.append(ap)\n",
    "    \n",
    "    map_score = sum(average_precision_scores) / len(average_precision_scores) if average_precision_scores else 0.0\n",
    "    return map_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Υπολογισμός του Average Precision (AP)**: \n",
    "\n",
    "Η συνάρτηση `average_precision` υπολογίζει το AP για κάθε query, μετρώντας την ακρίβεια σε κάθε θέση στην κατάταξη των αποτελεσμάτων και παίρνοντας τον μέσο όρο αυτών των τιμών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Συνάρτηση για τον υπολογισμό του Average Precision (AP) για ένα μόνο query\n",
    "def average_precision(retrieved_docs, relevant_docs):\n",
    "    retrieved_docs = list(retrieved_docs)\n",
    "    relevant_docs_set = set(relevant_docs.keys())\n",
    "    relevant_count = 0\n",
    "    precision_at_k = []\n",
    "    \n",
    "    for i, doc in enumerate(retrieved_docs, start=1):\n",
    "        if doc in relevant_docs_set:\n",
    "            relevant_count += 1\n",
    "            precision_at_k.append(relevant_count / i)\n",
    "    \n",
    "    ap = sum(precision_at_k) / len(relevant_docs) if relevant_docs else 0.0\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Αξιολόγηση της Μηχανής Αναζήτησης**:\n",
    "\n",
    "Η συνάρτηση `evaluate_search_engine` αξιολογεί τη μηχανή αναζήτησης για μια σειρά από queries. Για κάθε query, χρησιμοποιείται η συνάρτηση `boolean_query_processor` για να βρούμε τα έγγραφα που ταιριάζουν με το query και στη συνέχεια υπολογίζονται οι επιδόσεις (precision, recall, F1-Score).\n",
    "\n",
    "Επίσης, αποθηκεύονται τα αποτελέσματα των queries για τον υπολογισμό του Mean Average Precision (MAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Συνάρτηση για την αξιολόγηση της μηχανής αναζήτησης για μια σειρά queries\n",
    "def evaluate_search_engine(inverted_index):\n",
    "    queries = [\n",
    "        \"python AND java\",\n",
    "        \"content OR jump\",\n",
    "        \"python NOT java\"\n",
    "    ]\n",
    "    \n",
    "    relevant_docs_for_queries = {\n",
    "        \"python AND java\": {\n",
    "            \"https://en.wikipedia.org/wiki/Python_(programming_language)\": 1,\n",
    "            \"https://en.wikipedia.org/wiki/Java_(programming_language)\": 1\n",
    "        },\n",
    "        \"content OR jump\": {\n",
    "            \"https://en.wikipedia.org/wiki/Python_(programming_language)\": 1,\n",
    "            \"https://en.wikipedia.org/wiki/JavaScript\": 1\n",
    "        },\n",
    "        \"python NOT java\": {\n",
    "            \"https://en.wikipedia.org/wiki/Python_(programming_language)\": 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "    query_results = {}\n",
    "    print(\"Αποτελέσματα Αξιολόγησης:\\n\")\n",
    "    for query in queries:\n",
    "        print(f\"Ερώτημα: {query}\")\n",
    "        matching_docs = boolean_query_processor(query, inverted_index)\n",
    "        relevant_docs = relevant_docs_for_queries.get(query, {})\n",
    "        precision, recall, f1_score = evaluate_metrics(matching_docs, relevant_docs)\n",
    "        \n",
    "        print(f\"Ταιριαστά Έγγραφα: {matching_docs}\")\n",
    "        print(f\"Ακρίβεια: {precision:.2f}\")\n",
    "        print(f\"Ανάκτηση: {recall:.2f}\")\n",
    "        print(f\"F1-Score: {f1_score:.2f}\\n\")\n",
    "        \n",
    "        # Αποθήκευση των αποτελεσμάτων των queries για τον υπολογισμό του MAP\n",
    "        query_results[query] = matching_docs\n",
    "\n",
    "    # Υπολογισμός του Mean Average Precision (MAP)\n",
    "    map_score = mean_average_precision(query_results, relevant_docs_for_queries)\n",
    "    print(f\"Mean Average Precision (MAP): {map_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Κύρια Συνάρτηση**:\n",
    "\n",
    "Η κύρια συνάρτηση `main` φορτώνει το ανεστραμμένο ευρετήριο από το αρχείο *inverted_index.json* και αν είναι έγκυρο, καλεί τη συνάρτηση `evaluate_search_engine` για να αξιολογήσει τη μηχανή αναζήτησης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Κύρια συνάρτηση για τη φόρτωση του ανεστραμμένου ευρετηρίου και την εκτέλεση της αξιολόγησης\n",
    "def main():\n",
    "    inverted_index = load_inverted_index('inverted_index.json')\n",
    "    if inverted_index is not None:\n",
    "        evaluate_search_engine(inverted_index)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step 5](./project/images/step_5.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
